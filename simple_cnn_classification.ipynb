{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","#import os\n","#for dirname, _, filenames in os.walk('/kaggle/input'):\n","#    for filename in filenames:\n","#        print(os.path.join(dirname, filename))\n","        \n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"tags":[]},"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Conv2DTranspose, BatchNormalization, UpSampling2D, Reshape, Dropout\n","from keras import backend as K\n","from keras.utils import to_categorical"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":"Using TensorFlow backend.\n"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["df_train =  pd.read_csv('data/train_labels.csv')\n","df_train"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":"                                     filename  width  height  \\\n0      00000000a9764df2_20191005_085747_4.png    524     750   \n1      00000000a9764df2_20191005_085747_4.png    524     750   \n2      00000000a9764df2_20191005_085747_4.png    524     750   \n3      00000000a9764df2_20191005_085747_4.png    524     750   \n4      00000000a9764df2_20191005_085747_4.png    524     750   \n...                                       ...    ...     ...   \n11075  00000000a9764df2_20191003_163704_4.png    524     750   \n11076  00000000a9764df2_20191003_163704_4.png    524     750   \n11077  00000000a9764df2_20191003_163704_4.png    524     750   \n11078  00000000a9764df2_20191003_163704_4.png    524     750   \n11079  00000000a9764df2_20191003_163704_4.png    524     750   \n\n                  class  xmin  ymin  xmax  ymax  \n0        cappy_portakal    60     7   210    90  \n1      fuse_tea_seftali   217     1   396    78  \n2        johnnie_walker   390     1   439   155  \n3                miller    65    86   387   199  \n4            kinder_joy   438    83   503   193  \n...                 ...   ...   ...   ...   ...  \n11075           campari   383    26   452   176  \n11076           baileys    68   189   215   251  \n11077            kahlua    97   519   223   567  \n11078         beefeater   409   534   471   664  \n11079    johnnie_walker    65   667   219   747  \n\n[11080 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000000a9764df2_20191005_085747_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>cappy_portakal</td>\n      <td>60</td>\n      <td>7</td>\n      <td>210</td>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000000a9764df2_20191005_085747_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>fuse_tea_seftali</td>\n      <td>217</td>\n      <td>1</td>\n      <td>396</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000000a9764df2_20191005_085747_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>johnnie_walker</td>\n      <td>390</td>\n      <td>1</td>\n      <td>439</td>\n      <td>155</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000000a9764df2_20191005_085747_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>miller</td>\n      <td>65</td>\n      <td>86</td>\n      <td>387</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000000a9764df2_20191005_085747_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>kinder_joy</td>\n      <td>438</td>\n      <td>83</td>\n      <td>503</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11075</th>\n      <td>00000000a9764df2_20191003_163704_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>campari</td>\n      <td>383</td>\n      <td>26</td>\n      <td>452</td>\n      <td>176</td>\n    </tr>\n    <tr>\n      <th>11076</th>\n      <td>00000000a9764df2_20191003_163704_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>baileys</td>\n      <td>68</td>\n      <td>189</td>\n      <td>215</td>\n      <td>251</td>\n    </tr>\n    <tr>\n      <th>11077</th>\n      <td>00000000a9764df2_20191003_163704_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>kahlua</td>\n      <td>97</td>\n      <td>519</td>\n      <td>223</td>\n      <td>567</td>\n    </tr>\n    <tr>\n      <th>11078</th>\n      <td>00000000a9764df2_20191003_163704_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>beefeater</td>\n      <td>409</td>\n      <td>534</td>\n      <td>471</td>\n      <td>664</td>\n    </tr>\n    <tr>\n      <th>11079</th>\n      <td>00000000a9764df2_20191003_163704_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>johnnie_walker</td>\n      <td>65</td>\n      <td>667</td>\n      <td>219</td>\n      <td>747</td>\n    </tr>\n  </tbody>\n</table>\n<p>11080 rows Ã— 8 columns</p>\n</div>"},"metadata":{},"execution_count":3}]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_test =  pd.read_csv('data/test_labels.csv')\n","df_test"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":"                                    filename  width  height  \\\n0     00000000a9764df2_20191005_030806_4.png    524     750   \n1     00000000a9764df2_20191005_030806_4.png    524     750   \n2     00000000a9764df2_20191005_030806_4.png    524     750   \n3     00000000a9764df2_20191005_030806_4.png    524     750   \n4     00000000a9764df2_20191005_030806_4.png    524     750   \n...                                      ...    ...     ...   \n3995  00000000a9764df2_20191003_190301_4.png    524     750   \n3996  00000000a9764df2_20191003_190301_4.png    524     750   \n3997  00000000a9764df2_20191003_190301_4.png    524     750   \n3998  00000000a9764df2_20191003_190301_4.png    524     750   \n3999  00000000a9764df2_20191003_190301_4.png    524     750   \n\n                      class  xmin  ymin  xmax  ymax  \n0            nescafe_xpress    57     7   225    88  \n1                      burn   231     1   424    74  \n2                    sprite    65   116   250   196  \n3                     fanta   280    75   463   188  \n4     tadim_kavrulmus_badem    65   501   206   686  \n...                     ...   ...   ...   ...   ...  \n3995              efes_malt    60   320   452   441  \n3996     redbull_sugar_free    81   501   260   565  \n3997        efes_extra_shot   344   500   468   552  \n3998                  pepsi    64   590   249   683  \n3999         lipton_ice_tea   292   559   468   678  \n\n[4000 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000000a9764df2_20191005_030806_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>nescafe_xpress</td>\n      <td>57</td>\n      <td>7</td>\n      <td>225</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000000a9764df2_20191005_030806_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>burn</td>\n      <td>231</td>\n      <td>1</td>\n      <td>424</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000000a9764df2_20191005_030806_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>sprite</td>\n      <td>65</td>\n      <td>116</td>\n      <td>250</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000000a9764df2_20191005_030806_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>fanta</td>\n      <td>280</td>\n      <td>75</td>\n      <td>463</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000000a9764df2_20191005_030806_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>tadim_kavrulmus_badem</td>\n      <td>65</td>\n      <td>501</td>\n      <td>206</td>\n      <td>686</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>00000000a9764df2_20191003_190301_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>efes_malt</td>\n      <td>60</td>\n      <td>320</td>\n      <td>452</td>\n      <td>441</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>00000000a9764df2_20191003_190301_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>redbull_sugar_free</td>\n      <td>81</td>\n      <td>501</td>\n      <td>260</td>\n      <td>565</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>00000000a9764df2_20191003_190301_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>efes_extra_shot</td>\n      <td>344</td>\n      <td>500</td>\n      <td>468</td>\n      <td>552</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>00000000a9764df2_20191003_190301_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>pepsi</td>\n      <td>64</td>\n      <td>590</td>\n      <td>249</td>\n      <td>683</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>00000000a9764df2_20191003_190301_4.png</td>\n      <td>524</td>\n      <td>750</td>\n      <td>lipton_ice_tea</td>\n      <td>292</td>\n      <td>559</td>\n      <td>468</td>\n      <td>678</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows Ã— 8 columns</p>\n</div>"},"metadata":{},"execution_count":4}]},{"metadata":{"trusted":true},"cell_type":"code","source":["def decouple(df):\n","    matrix = {}\n","    classes = {}\n","    for index, row in df.iterrows():\n","        if row['filename'] not in matrix:\n","            matrix[row['filename']] = {'count':0}\n","        if row['class'] not in matrix[row['filename']]:\n","            matrix[row['filename']][row['class']] = 1\n","        else:\n","            matrix[row['filename']][row['class']] += 1\n","        matrix[row['filename']]['count'] += 1\n","\n","        if row['class'] not in classes:\n","            classes[row['class']] = 1\n","        else:\n","            classes[row['class']] += 1\n","    #classes = {k: v for k, v in sorted(classes.items(), key=lambda item: item[1])}            \n","    return matrix,classes"],"execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["matrix_train,classes_train = decouple(df_train)\n","matrix_test,classes_test = decouple(df_test)"],"execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"tags":[]},"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,validation_split=0.2)\n","\n","train_generator = train_datagen.flow_from_dataframe(\n","        dataframe=df_train,\n","        directory='data/train',\n","        x_col='filename',\n","        y_col='class',\n","        target_size=(440, 440),\n","        batch_size=8,\n","        class_mode='categorical',\n","        subset=\"training\",)\n","\n","validation_generator = train_datagen.flow_from_dataframe(\n","        dataframe=df_train,\n","        directory='data/train',\n","        x_col='filename',\n","        y_col='class',\n","        target_size=(440, 440),\n","        batch_size=8,\n","        class_mode='categorical',\n","        subset=\"validation\",)\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"Found 8864 validated image filenames belonging to 40 classes.\nFound 2216 validated image filenames belonging to 40 classes.\n"}]},{"metadata":{"trusted":true,"tags":[]},"cell_type":"code","source":["model = Sequential()\n","\n","# Step 1 - Convolution\n","model.add(Conv2D(32, (3, 3), padding='same', input_shape = (440, 440, 3), activation = 'relu'))\n","model.add(Conv2D(32, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5)) # antes era 0.25\n","# Adding a second convolutional layer\n","model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5)) # antes era 0.25\n","# Adding a third convolutional layer\n","model.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5)) # antes era 0.25\n","# Step 3 - Flattening\n","model.add(Flatten())\n","# Step 4 - Full connection\n","model.add(Dense(units = 512, activation = 'relu'))\n","model.add(Dropout(0.5)) \n","model.add(Dense(units = 40, activation = 'softmax'))\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","model.save(\"simple_cnn_classification.h5\")"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 440, 440, 32)      896       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 438, 438, 32)      9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 219, 219, 32)      0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 219, 219, 32)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 219, 219, 64)      18496     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 217, 217, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 108, 108, 64)      0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 108, 108, 64)      0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 108, 108, 64)      36928     \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 106, 106, 64)      36928     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 53, 53, 64)        0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 53, 53, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 179776)            0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               92045824  \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 40)                20520     \n=================================================================\nTotal params: 92,205,768\nTrainable params: 92,205,768\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.layers[0].input_shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":"(None, 440, 440, 3)"},"metadata":{},"execution_count":10}]},{"metadata":{"trusted":true,"tags":[]},"cell_type":"code","source":["history = model.fit_generator(\n","        train_generator,\n","        #steps_per_epoch=100,\n","        epochs=1,\n","        #steps_per_epoch=100,\n","        validation_data=validation_generator,\n","        #validation_steps=100\n","        )\n","model.save(\"simple_cnn_classification.h5\")"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/1\n 236/1108 [=====>........................] - ETA: 1:26:56 - loss: 3.6707 - accuracy: 0.0461"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a8904cd64cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#steps_per_epoch=100,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#validation_steps=100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         )\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(acc) + 1)\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python37264bit3ef340d3d96f44f381aa898ad19adcf0","display_name":"Python 3.7.2 64-bit","language":"python"},"language_info":{"name":"python","version":"3.7.2-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}